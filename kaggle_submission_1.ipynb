{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8683b2-2620-4e5b-8825-f0215d4ac79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/pyspellchecker/pyspellchecker-0.8.4-py3-none-any.whl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "import seaborn as sns\n",
    "import warnings   # We will turn of the future warnings that xgboost gives us\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings   \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89b625-df48-4425-a084-8cf94fbbe310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets here. \n",
    "\n",
    "train_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv', index_col='id')\n",
    "test_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv', index_col='id')\n",
    "sample_sub = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/train-final/train_WORK.csv\", sep=',', index_col = 'id')\n",
    "\n",
    "train_y = train['generated']\n",
    "train_X = train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399340f1-fb6a-40e0-acda-860e46f18ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"].str.lower()\n",
    "\n",
    "# Define inputs for variables \n",
    "\n",
    "input_transition = [\"first\", \"firstly\", \"second\", \"secondly\", \"third\", \"thirdly\", \"meanwhile\", \"previously\", \"subsequently\", \"eventually\", \n",
    "                    \"finally\", \"lastly\", \"ultimately\", \"conclusion\", \"addition\", \"additionally\", \"furthermore\", \"moreover\", \"besides\", \n",
    "                    \"equally\", \"however\", \"contrary\", \"conversely\", \"despite\", \"contrast\", \"nevertheless\", \"nonetheless\", \"whereas\", \"while\",\n",
    "                    \"although\", \"though\", \"therefore\", \"thus\", \"hence\", \"consequently\", \"accordingly\", \"namely\", \"specifically\", \"indeed\", \n",
    "                    \"importantly\", \"significantly\", \"especially\", \"notably\", \"undoubtedly\", \"likewise\", \"similarly\", \"correspondingly\", \"sum\",\n",
    "                    \"summary\", \"overall\", \"conclude\", \"conclusion\", \"simultaneously\", \"formerly\", \"lately\", \"recently\", \"opposite\", \"adjacent\",\n",
    "                    \"provided\", \"admittedly\", \"regarding\"]\n",
    "\n",
    "input_hyperbole = [\"powerful\", \"groundbreaking\", \"illuminating\", \"vital\", \"invaluable\", \"indelible\", \"essential\", \"poignant\", \"profound\", \n",
    "                   \"remarkable\", \"transformative\", \"revolutionary\", \"unparalleled\", \"extraordinary\", \"compelling\", \"significant\", \"exceptional\",\n",
    "                   \"crucial\", \"monumental\", \"dramatic\", \"robust\", \"innovative\", \"pivotal\", \"impressive\", \"astonishing\", \"visionary\", \"inspiring\",\n",
    "                   \"striking\", \"dynamic\", \"iconic\", \"seminal\", \"trailblazing\", \"revolutionary\", \"extreme\", \"shocking\"]\n",
    "\n",
    "input_abn_symbols = [\"[\", \"]\", \"_\", \"*\", \"<\", \">\", \"{\", \"}\", \"^\", \"@\", \"#\", \"|\", \"\\\\\"]\n",
    "\n",
    "input_prompt_lang = [\"here you go\", \"as an ai\", \"as a language model\", \"i generated\", \"here's the essay\", \"here's your essay\", \"let me\", \n",
    "                     \"help you\", \"sure,\", \"i hope this helps\", \"your prompt\", \"your request\", \"here is\", \"here's\", \"sure!\", \n",
    "                     \"here is the essay\", \"here is your essay\", \"language model\", \"large language\", \"llm\", \"generative ai\", \"chatbot\", \n",
    "                     \"your essay\"]\n",
    "\n",
    "# Create new variables \n",
    "\n",
    "### Spelling errors\n",
    "spell = SpellChecker()\n",
    "\n",
    "def clean_text_for_spellcheck(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    for symbol in input_abn_symbols:\n",
    "        text = text.replace(symbol, \"\")\n",
    "    text = re.sub(r\"[^a-z\\s'-]\", \"\", text.lower())\n",
    "    return text\n",
    "\n",
    "def misspelling_ratio(text):\n",
    "    text_clean = clean_text_for_spellcheck(text)\n",
    "    words = text_clean.split()\n",
    "    if len(words) == 0:\n",
    "        return 0.0 \n",
    "    misspelled = spell.unknown(words)\n",
    "    return len(misspelled) / len(words)\n",
    "\n",
    "def count_misspellings(text):\n",
    "    text_clean = clean_text_for_spellcheck(text)\n",
    "    words = text_clean.split()\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    misspelled = spell.unknown(words)\n",
    "    return len(misspelled)\n",
    "\n",
    "\n",
    "train[\"text_modified\"] = train[\"text\"].apply(clean_text_for_spellcheck)\n",
    "train[\"misspelling_ratio\"] = train[\"text_modified\"].apply(misspelling_ratio)\n",
    "train[\"n_misspellings\"] = train[\"text_modified\"].apply(count_misspellings)\n",
    "\n",
    "### Exclamation points\n",
    "def count_exclamation_points(text):\n",
    "    return text.count('!')\n",
    "train[\"n_exclamations\"] = train[\"text\"].apply(count_exclamation_points)\n",
    "\n",
    "\n",
    "### Em dashes\n",
    "def count_em_dash(text):\n",
    "    return text.count('â€”')\n",
    "train[\"n_em_dash\"] = train[\"text\"].apply(count_em_dash)\n",
    "\n",
    "\n",
    "### Transitional words\n",
    "def count_transition(text):\n",
    "    return sum(text.count(word) for word in input_transition)\n",
    "train[\"n_transition_words\"] = train[\"text\"].apply(count_transition)\n",
    "\n",
    "\n",
    "### Hyperbolic phrasing\n",
    "def count_hyperbolic(text):\n",
    "    return sum(text.count(word) for word in input_hyperbole)\n",
    "train[\"n_hyperbolic\"] = train[\"text\"].apply(count_hyperbolic)\n",
    "\n",
    "\n",
    "### Abnormal symbols\n",
    "def count_abn_symbols(text):\n",
    "    return sum(text.count(word) for word in input_abn_symbols)\n",
    "train[\"n_abn_symbols\"] = train[\"text\"].apply(count_abn_symbols)\n",
    "\n",
    "\n",
    "## Prompt indicator\n",
    "def contains_prompt_indicators(text):\n",
    "    return sum(text.count(word) for word in input_prompt_lang)\n",
    "train[\"n_prompt_indicator\"] = train[\"text\"].apply(contains_prompt_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d604da-d028-4c47-b5c5-9bf9c394d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'n_prompt_indicator',\n",
    "    'n_misspellings',\n",
    "    'n_exclamations',\n",
    "    'n_em_dash',\n",
    "    'n_abn_symbols',\n",
    "    'n_transition_words',\n",
    "    'n_hyperbolic',\n",
    "    'misspelling_ratio'\n",
    "]\n",
    "\n",
    "X_train_features = train[feature_cols]\n",
    "y_train = train['generated']\n",
    "\n",
    "preprocess = Pipeline([\n",
    "    ('scale', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36a28d-1a34-475d-8cae-85934f0a4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forests pipe - no PCA\n",
    "pipe_rf = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params_rf = {\n",
    "    \"model\": [RandomForestClassifier(random_state=38)],\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__max_depth\": [None, 5, 10],\n",
    "    \"model__min_samples_split\": [5, 10, 20],\n",
    "    \"model__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipe_rf, params_rf, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train_features, y_train)\n",
    "\n",
    "# XGB pipe\n",
    "pipe_xgb = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('model', XGBClassifier())\n",
    "])\n",
    "\n",
    "params_xgb = {\n",
    "    \"model\": [XGBClassifier(eval_metric='logloss', random_state=38)],\n",
    "    \"model__learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__max_depth\": [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(pipe_xgb, params_xgb, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "grid_xgb.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0191ed1-45d7-4597-b508-6ec9c3911e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = max([grid_rf, grid_xgb], key=lambda g: g.best_score_)\n",
    "pipe_final = best_grid.best_estimator_\n",
    "pipe_final.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0a0624-cb35-4341-9eeb-aecaf33aee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_essays[\"text_modified\"] = test_essays[\"text\"].apply(clean_text_for_spellcheck)\n",
    "test_essays['misspelling_ratio'] = test_essays['text'].apply(misspelling_ratio)\n",
    "test_essays['n_misspellings'] = test_essays['text'].apply(count_misspellings)\n",
    "test_essays['n_exclamations'] = test_essays['text'].apply(count_exclamation_points)\n",
    "test_essays['n_em_dash'] = test_essays['text'].apply(count_em_dash)\n",
    "test_essays['n_transition_words'] = test_essays['text'].apply(count_transition)\n",
    "test_essays['n_hyperbolic'] = test_essays['text'].apply(count_hyperbolic)\n",
    "test_essays['n_abn_symbols'] = test_essays['text'].apply(count_abn_symbols)\n",
    "test_essays[\"n_prompt_indicator\"] = test_essays[\"text\"].apply(contains_prompt_indicators)\n",
    "\n",
    "X_test_features = test_essays[feature_cols]\n",
    "\n",
    "test_preds = pipe_final.predict(X_test_features)\n",
    "\n",
    "final_submission = pd.DataFrame({\n",
    "    'id': sample_sub['id'],   # keep Kaggle ids intact\n",
    "    'generated': test_preds\n",
    "})\n",
    "\n",
    "final_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
