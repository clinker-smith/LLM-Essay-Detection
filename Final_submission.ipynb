{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ded7f3",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Names: Sophia Hillard & Campbell Linker\n",
    "\n",
    "- Insert Markdown chunks for your written responses as needed\n",
    "- Do not include unnecessary code. Only code that is needed to answer the questions should be included, nothing more. \n",
    "- Be sure your work is **reproducible** by \"Restart and Clear Output\" then \"Run All\" cells\n",
    "- The group leader will make a single submission on Moodle on behalf of the group. \n",
    "- **ACKNOWELDGE ALL EXTERNAL SOURCES HERE:** Give a brief summary of any external sources you used. Ex:\n",
    "    - https://pankaj8blr.medium.com/eda-and-significance-of-various-plots-in-feature-engineering-f8cededbd520\n",
    "    - https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "    - Google AI overview for XXX\n",
    "    - StackOverflow for YYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6b0ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings   \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcddc3a9",
   "metadata": {},
   "source": [
    "## 1. The Data\n",
    "\n",
    "The dataset we chose is [LLM - Detect AI Generated Text](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/overview) where:\n",
    "\n",
    "* Outcome variable: Binary, AI generated (1) or human generated (0)\n",
    "* Predictor variables: -- all created through feature engineering of essay text\n",
    "* Number of observations:\n",
    "    * Training set: $n_{train} = 9000$ ($1000$ from competition training set, $8000$ from [reccomended external source](https://www.kaggle.com/datasets/thedrcat/daigt-v2-train-dataset))\n",
    "    * Test set: $n_{test} = 9000$\n",
    "* Score/metric used for the [leaderboard](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/leaderboard): Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9575fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets here. \n",
    "train = pd.read_csv(\"data/all-DAIGT-training.csv\", sep=',', index_col = 'id') # see write-up for data provenance\n",
    "test_essays = pd.read_csv('data/test_essays.csv', index_col='id')\n",
    "example = pd.read_csv('data/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4f352",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Perform all necessary EDA here. Before submitting, only keep those you feel are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c967bdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the first argument must be callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4d/7b0yj4wd7fn526lmxmh7l7f40000gn/T/ipykernel_51517/3834612316.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Univariate visualization of outcome variable:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Generated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Student-Authored'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcategory_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategory_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategory_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprop_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10461\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10463\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10465\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the first argument must be callable"
     ]
    }
   ],
   "source": [
    "# Univariate visualization of outcome variable:\n",
    "y_train_cat = train.map({1: 'Generated', 0: 'Student-Authored'})\n",
    "category_counts = pd.Series(y_train_cat).value_counts()\n",
    "plt.bar(x = category_counts.index, height = category_counts.values)\n",
    "prop_gen = train.mean()\n",
    "plt.title(\"Proportion Generated: \" + str(f\"{prop_gen:.4f}\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e56f37",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Perform your feature engineering here and then create `y_train`, `X_train` and `X_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94ce9338-08fa-457a-9d9d-62a83b383783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs for variables \n",
    "\n",
    "input_transition = [\"first\", \"firstly\", \"second\", \"secondly\", \"third\", \"thirdly\", \"meanwhile\", \"previously\", \"subsequently\", \"eventually\", \n",
    "                    \"finally\", \"lastly\", \"ultimately\", \"conclusion\", \"addition\", \"additionally\", \"furthermore\", \"moreover\", \"besides\", \n",
    "                    \"equally\", \"however\", \"contrary\", \"conversely\", \"despite\", \"contrast\", \"nevertheless\", \"nonetheless\", \"whereas\", \"while\",\n",
    "                    \"although\", \"though\", \"therefore\", \"thus\", \"hence\", \"consequently\", \"accordingly\", \"namely\", \"specifically\", \"indeed\", \n",
    "                    \"importantly\", \"significantly\", \"especially\", \"notably\", \"undoubtedly\", \"likewise\", \"similarly\", \"correspondingly\", \"sum\",\n",
    "                    \"summary\", \"overall\", \"conclude\", \"conclusion\", \"simultaneously\", \"formerly\", \"lately\", \"recently\", \"opposite\", \"adjacent\",\n",
    "                    \"provided\", \"admittedly\", \"regarding\"]\n",
    "\n",
    "input_hyperbole = [\"powerful\", \"groundbreaking\", \"illuminating\", \"vital\", \"invaluable\", \"indelible\", \"essential\", \"poignant\", \"profound\", \n",
    "                   \"remarkable\", \"transformative\", \"revolutionary\", \"unparalleled\", \"extraordinary\", \"compelling\", \"significant\", \"exceptional\",\n",
    "                   \"crucial\", \"monumental\", \"dramatic\", \"robust\", \"innovative\", \"pivotal\", \"impressive\", \"astonishing\", \"visionary\", \"inspiring\",\n",
    "                   \"striking\", \"dynamic\", \"iconic\", \"seminal\", \"trailblazing\", \"revolutionary\", \"extreme\", \"shocking\"]\n",
    "\n",
    "input_abn_symbols = [\"[\", \"]\", \"_\", \"*\", \"<\", \">\", \"{\", \"}\", \"^\", \"@\", \"#\", \"|\", \"\\\\\"]\n",
    "\n",
    "input_prompt_lang = [\"here you go\", \"as an ai\", \"as a language model\", \"i generated\", \"here's the essay\", \"here's your essay\", \"let me\", \n",
    "                     \"help you\", \"sure,\", \"i hope this helps\", \"your prompt\", \"your request\", \"here is\", \"here's\", \"sure!\", \n",
    "                     \"here is the essay\", \"here is your essay\", \"language model\", \"large language\", \"llm\", \"generative ai\", \"chatbot\", \n",
    "                     \"your essay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f70da207-5f9b-45d6-849f-4d25b55cebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for feature engineering \n",
    "\n",
    "### Spelling errors\n",
    "spell = SpellChecker()\n",
    "\n",
    "def clean_text_for_spellcheck(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    for symbol in input_abn_symbols:\n",
    "        text = text.replace(symbol, \"\")\n",
    "    text = re.sub(r\"[^a-z\\s'-]\", \"\", text.lower())\n",
    "    return text\n",
    "\n",
    "def misspelling_ratio(text):\n",
    "    text_clean = clean_text_for_spellcheck(text)\n",
    "    words = text_clean.split()\n",
    "    if len(words) == 0:\n",
    "        return 0.0 \n",
    "    misspelled = spell.unknown(words)\n",
    "    return len(misspelled) / len(words)\n",
    "\n",
    "def count_misspellings(text):\n",
    "    text_clean = clean_text_for_spellcheck(text)\n",
    "    words = text_clean.split()\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    misspelled = spell.unknown(words)\n",
    "    return len(misspelled)\n",
    "\n",
    "### Exclamation points\n",
    "def count_exclamation_points(text):\n",
    "    return text.count('!')\n",
    "\n",
    "\n",
    "### Em dashes\n",
    "def count_em_dash(text):\n",
    "    return text.count('â€”')\n",
    "\n",
    "\n",
    "### Transitional words\n",
    "def count_transition(text):\n",
    "    return sum(text.count(word) for word in input_transition)\n",
    "\n",
    "\n",
    "### Hyperbolic phrasing\n",
    "def count_hyperbolic(text):\n",
    "    return sum(text.count(word) for word in input_hyperbole)\n",
    "\n",
    "\n",
    "### Abnormal symbols\n",
    "def count_abn_symbols(text):\n",
    "    return sum(text.count(word) for word in input_abn_symbols)\n",
    "\n",
    "\n",
    "## Prompt indicator\n",
    "def contains_prompt_indicators(text):\n",
    "    return sum(text.count(word) for word in input_prompt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cca0a5f-5ff5-4353-b4e1-7cc4dcdb9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features to both training AND competition test data\n",
    "\n",
    "def add_features(df):\n",
    "    # making sure to include a step that makes all text lowercase so that features can be applied\n",
    "    df[\"text\"] = df[\"text\"].str.lower()  \n",
    "    df[\"misspelling_ratio\"] = df[\"text\"].apply(misspelling_ratio)\n",
    "    df[\"n_misspellings\"] = df[\"text\"].apply(count_misspellings)\n",
    "    df[\"n_exclamations\"] = df[\"text\"].apply(count_exclamation_points)\n",
    "    df[\"n_em_dash\"] = df[\"text\"].apply(count_em_dash)\n",
    "    df[\"n_transition\"] = df[\"text\"].apply(count_transition)\n",
    "    df[\"n_hyperbolic\"] = df[\"text\"].apply(count_hyperbolic)\n",
    "    df[\"n_abn_symbols\"] = df[\"text\"].apply(count_abn_symbols)\n",
    "    df[\"n_prompt\"] = df[\"text\"].apply(contains_prompt_indicators)\n",
    "\n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "test_essays = add_features(test_essays)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cacf85d-f4cb-40f5-9802-775dded20d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>model</th>\n",
       "      <th>misspelling_ratio</th>\n",
       "      <th>n_misspellings</th>\n",
       "      <th>n_exclamations</th>\n",
       "      <th>n_em_dash</th>\n",
       "      <th>n_transition</th>\n",
       "      <th>n_hyperbolic</th>\n",
       "      <th>n_abn_symbols</th>\n",
       "      <th>n_prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d429f032</th>\n",
       "      <td>advantages of limiting car usage \\n\\nlimiting ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ce279be</th>\n",
       "      <td>advantages of limiting car usage\\n\\nlimiting c...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9595213</th>\n",
       "      <td>limiting car usage has numerous advantages tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2266d87</th>\n",
       "      <td>the passages provided discuss the advantages o...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eeace4bd</th>\n",
       "      <td>title: the advantages of limiting car usage\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.014625</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354fdce0</th>\n",
       "      <td>advantages of limiting car usage\\n\\nlimiting c...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6eaa842f</th>\n",
       "      <td>the advantages of limiting car usage are becom...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a36a04d5</th>\n",
       "      <td>limiting car usage has numerous advantages for...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9d5567f</th>\n",
       "      <td>advantages of limiting car usage\\n\\nlimiting c...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2e2ead1</th>\n",
       "      <td>the advantages of limiting car usage\\n\\nin rec...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9408e5f4</th>\n",
       "      <td>it is becoming increasingly evident that there...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee18417a</th>\n",
       "      <td>explanatory essay: the advantages of limiting ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35f1f42a</th>\n",
       "      <td>title: the advantages of limiting car usage\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55652348</th>\n",
       "      <td>limiting car usage offers numerous advantages ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72a3909f</th>\n",
       "      <td>advantages of limiting car usage\\n\\nin recent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  generated  \\\n",
       "id                                                                       \n",
       "d429f032  advantages of limiting car usage \\n\\nlimiting ...          1   \n",
       "1ce279be  advantages of limiting car usage\\n\\nlimiting c...          1   \n",
       "c9595213  limiting car usage has numerous advantages tha...          1   \n",
       "f2266d87  the passages provided discuss the advantages o...          1   \n",
       "eeace4bd  title: the advantages of limiting car usage\\n\\...          1   \n",
       "354fdce0  advantages of limiting car usage\\n\\nlimiting c...          1   \n",
       "6eaa842f  the advantages of limiting car usage are becom...          1   \n",
       "a36a04d5  limiting car usage has numerous advantages for...          1   \n",
       "c9d5567f  advantages of limiting car usage\\n\\nlimiting c...          1   \n",
       "c2e2ead1  the advantages of limiting car usage\\n\\nin rec...          1   \n",
       "9408e5f4  it is becoming increasingly evident that there...          1   \n",
       "ee18417a  explanatory essay: the advantages of limiting ...          1   \n",
       "35f1f42a  title: the advantages of limiting car usage\\n\\...          1   \n",
       "55652348  limiting car usage offers numerous advantages ...          1   \n",
       "72a3909f  advantages of limiting car usage\\n\\nin recent ...          1   \n",
       "\n",
       "                  model  misspelling_ratio  n_misspellings  n_exclamations  \\\n",
       "id                                                                           \n",
       "d429f032  gpt-3.5-turbo           0.007712               3               0   \n",
       "1ce279be  gpt-3.5-turbo           0.011442               5               0   \n",
       "c9595213  gpt-3.5-turbo           0.016327               8               0   \n",
       "f2266d87  gpt-3.5-turbo           0.007634               3               0   \n",
       "eeace4bd  gpt-3.5-turbo           0.014625               8               0   \n",
       "354fdce0  gpt-3.5-turbo           0.013483               6               0   \n",
       "6eaa842f  gpt-3.5-turbo           0.018672               9               0   \n",
       "a36a04d5  gpt-3.5-turbo           0.019868               6               0   \n",
       "c9d5567f  gpt-3.5-turbo           0.014184               6               0   \n",
       "c2e2ead1  gpt-3.5-turbo           0.006316               3               0   \n",
       "9408e5f4  gpt-3.5-turbo           0.010352               5               0   \n",
       "ee18417a  gpt-3.5-turbo           0.006110               3               0   \n",
       "35f1f42a  gpt-3.5-turbo           0.004405               2               0   \n",
       "55652348  gpt-3.5-turbo           0.009091               5               0   \n",
       "72a3909f  gpt-3.5-turbo           0.011799               8               0   \n",
       "\n",
       "          n_em_dash  n_transition  n_hyperbolic  n_abn_symbols  n_prompt  \n",
       "id                                                                        \n",
       "d429f032          0             7             2              0         0  \n",
       "1ce279be          0             6             4              0         0  \n",
       "c9595213          0             9             2              0         0  \n",
       "f2266d87          0             4             0              0         0  \n",
       "eeace4bd          0             7             4              0         0  \n",
       "354fdce0          0             5             3              0         0  \n",
       "6eaa842f          0             5             2              0         0  \n",
       "a36a04d5          0             6             4              0         0  \n",
       "c9d5567f          0            10             3              0         0  \n",
       "c2e2ead1          0            10             3              0         0  \n",
       "9408e5f4          0             6             5              0         0  \n",
       "ee18417a          0             9             5              0         1  \n",
       "35f1f42a          0             6             5              0         0  \n",
       "55652348          0             5             6              0         0  \n",
       "72a3909f          0            11             3              0         0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['prompt_id', 'kaggle_repo'], axis=1)\n",
    "train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad85c490-c1e1-4c5c-b1fb-cad421a7b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important for pre-processing -- define which of the predictors are our featured engineered ones since we are using tf-idf later\n",
    "\n",
    "our_features = [\n",
    "    \"misspelling_ratio\", \"n_misspellings\", \"n_exclamations\", \"n_em_dash\", \"n_transition\", \"n_hyperbolic\",\"n_abn_symbols\", \"n_prompt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ca4063",
   "metadata": {},
   "source": [
    "## 4. Data preparation pipelines and pre-processing\n",
    "\n",
    "Run all preparation and pre-processing pipelines here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27849082-8a20-4c9b-94fe-fa7cffb039c1",
   "metadata": {},
   "source": [
    "#### Splitting with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a04931d2-6631-4bf0-8994-b8ddabedf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train/test split\n",
    "train_essay, test_essay = train_test_split(train, test_size=0.3, random_state=38)\n",
    "\n",
    "# train\n",
    "train_y = train_essay['generated']\n",
    "train_X = train_essay.drop(columns='generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb9b75e9-2d17-4d20-9eef-048b44981b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF \n",
    "word_tfidf = TfidfVectorizer(stop_words='english', max_features=20000, ngram_range=(1,3), min_df=2)\n",
    "\n",
    "char_tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3,5), max_features=20000, min_df=2)\n",
    "\n",
    "# combine the two vectorizer steps -- used Google AI overview for this and the next step, was not previously familiar \n",
    "# with Feature Union and making a more complex preprocessor\n",
    "nlp_features = FeatureUnion([\n",
    "    ('word', word_tfidf),\n",
    "    ('char', char_tfidf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49029497-37a4-4cc3-83eb-bd5273776df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing step -- used Google AI overview for this step, as described above\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('nlp', nlp_features, 'text'),\n",
    "        ('our', StandardScaler(), our_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('model', XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8db1c34",
   "metadata": {},
   "source": [
    "## 5. Model selection and hyperparameter tuning\n",
    "\n",
    "Perform all model selection and hyperpareter tuning here. Create separate pipelines here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f051e-bb75-4ca6-b4b4-7e184527f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full grid search of all possible models\n",
    "### **important note*** this is not the exact code we used to run our comparison of models, this would've EXPLODED our computers!\n",
    "### we ran this model comparison grid search on preliminary training data (N=1000) and then as we advanced our sample size, \n",
    "### started to run grid search over independent models and their parameters individually, comparing AUC scores as our scoring \n",
    "### metric and evaluating performance on test data in kaggle. \n",
    "\n",
    "### this is formatted to represent all possible combos we tried, though it is not reflective of the multiple instances of \n",
    "### gridsearchcv we used\n",
    "\n",
    "\n",
    "# param_grid = [\n",
    "#    ENSEMBLE METHODS\n",
    "#    {\n",
    "#        \"model\": [RandomForestClassifier(random_state=38)],\n",
    "#        \"model__n_estimators\": [100, 200],\n",
    "#        \"model__max_depth\": [None, 5, 10],\n",
    "#        \"model__min_samples_split\": [5, 10, 20],\n",
    "#        \"model__class_weight\": [None, \"balanced\"]\n",
    "#    },\n",
    "#    {\n",
    "#        \"model\": [XGBClassifier(eval_metric='logloss', random_state=38)],\n",
    "#        \"model__learning_rate\": [0.05, 0.1],\n",
    "#        \"model__n_estimators\": [300, 500],\n",
    "#        \"model__max_depth\": [2, 3], \n",
    "#        \"model__reg_alpha\": [0, 0.1, 0.5],\n",
    "#        \"model__reg_lambda\": [3, 5]\n",
    "#    },\n",
    "#    LINEAR METHODS\n",
    "#    {\n",
    "#        \"model\": [LogisticRegression()],\n",
    "#        \"model__C\": [0.01, 0.05, 0.1, 0.5, 1, 2],\n",
    "#        \"model__penalty\": ['l1', 'l2'],\n",
    "#    }\n",
    "# ]\n",
    "\n",
    "# grid = GridSearchCV(pipe, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# grid.fit(train[['text'] + our_features], train['generated'])\n",
    "\n",
    "# print(\"Best score:\", grid.best_score_)\n",
    "# print(\"Best params:\", grid.best_params_)\n",
    "\n",
    "# pipe_final = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0aedc",
   "metadata": {},
   "source": [
    "## 6. Creation of final pipeline\n",
    "\n",
    "Create your final pipeline here and save it in an object called `pipe_final`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ac1bbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(76115) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76116) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76117) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76118) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76119) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76120) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76121) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76122) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel__learning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.2\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel__n_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel__max_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      8\u001b[0m grid_xgb \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m grid_xgb\u001b[38;5;241m.\u001b[39mfit(train_X, train_y)\n\u001b[1;32m     11\u001b[0m pipe_final \u001b[38;5;241m=\u001b[39m grid_xgb\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n\u001b[1;32m    919\u001b[0m         X,\n\u001b[1;32m    920\u001b[0m         y,\n\u001b[1;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m )\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "params = {\n",
    "    \"model__learning_rate\": [0.2],\n",
    "    \"model__n_estimators\": [200],\n",
    "    \"model__max_depth\": [3]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(pipe, params, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_xgb.fit(train_X, train_y)\n",
    "\n",
    "pipe_final = grid_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bdb16-be96-4332-8a33-1aec39ab19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = pipe_final.predict(test_X)\n",
    "test_probs = pipe_final.predict_proba(test_X)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc = roc_auc_score(test_y, test_probs)\n",
    "print(\"Test ROC-AUC:\", roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac81cc",
   "metadata": {},
   "source": [
    "## 7. Creating Submission\n",
    "\n",
    "* Using `pipe_final`, create a data frame `final_submission` that has your predictions and write to `final_submission.csv` that you can submit on Kaggle. Note the format of `final_submission.csv` has to match that `example_submission.csv` exactly.\n",
    "* Take a screen shot of your final leaderboard score and ensure it displays below\n",
    "* Run the `RepeatedKFold()` as you did in PS3. \n",
    "\n",
    "\n",
    "* Keep track of at least one score a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "918eb68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pipe_final to create final_submission data frame here:\n",
    "preds = pipe_final.predict(train_essay_X)\n",
    "\n",
    "final_submission = pd.DataFrame({\n",
    "    'essay_id': train_essay.index,  # Use the same index as in your train_essay DataFrame\n",
    "    'generated': preds\n",
    "})\n",
    "\n",
    "final_submission.to_csv('data/final_submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/leaderboard.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0539526",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cv_final \u001b[38;5;241m=\u001b[39m RepeatedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m38\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m scores_final \u001b[38;5;241m=\u001b[39m cross_val_score(pipe_final, X_train, y_train, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcv_final)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(scores_final)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe_final' is not defined"
     ]
    }
   ],
   "source": [
    "cv_final = RepeatedKFold(n_splits=5, n_repeats=10, random_state=38)\n",
    "scores_final = cross_val_score(pipe_final, X_train, y_train, scoring='accuracy', cv=cv_final)\n",
    "print(f'Mean accuracy: {np.mean(scores_final):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb5a36",
   "metadata": {},
   "source": [
    "## 8. Appendix\n",
    "\n",
    "Please anything extra that you don't feel is central, but would still like to keep here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987059b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
